# ğŸ§  TED AI Curator & Personal Assistant

An intelligent, multi-agent AI system designed to curate, recommend, and analyze TED Talks. Built with **Snowflake Cortex**, **LangGraph**, and **Airflow**, this project demonstrates a modern **RAG (Retrieval-Augmented Generation)** architecture suitable for enterprise-grade applications.

---

## ğŸ—ï¸ Architecture

The system follows a **Hub-and-Spoke** agentic architecture orchestrated by LangGraph:

```mermaid
graph TD
    User-->Router[Router Agent]
    Router-->|Intent: Search|Search[Semantic Search Agent]
    Router-->|Intent: Playlist|Playlist[Playlist Generator]
    Router-->|Intent: Compare|Compare[Comparison Agent]
    Router-->|Intent: Summarize|Sum[Video Summarizer]
    Router-->|Intent: QA|QA[QA Pipeline]
    
    Search-->Rank[Relevance Ranker]
    Rank-->Reason[Reasoning Engine]
    Reason-->Final[Response Formatter]
```

### Key Components
1.  **Data Ingestion (Airflow)**: Daily DAGs ingest TED Talk metadata, transcripts, and images from S3 into Snowflake `RAW` schema.
2.  **Transformation (DBT)**: Cleans and organizes data into a `CURATED` star schema (`DIM_TED_TALKS`, `FCT_TED_TALKS`).
3.  **Semantic Layer (Snowflake Cortex)**:
    *   Generates vector embeddings for all talks using `snowflake-arctic-embed-m`.
    *   Enables **Hybrid Search** (Keyword + Semantic Vector Search).
4.  **AI Orchestration (LangGraph)**:
    *   **Router Agent**: Classifies user intent (Learning Path vs. Specific Question).
    *   **Recommendation Agent**: Multi-step pipeline (Retrieval -> Re-ranking -> Reasoning) to ensure high-quality suggestions.
    *   **Comparison Agent**: Analyzes metadata and transcripts to compare two or more talks side-by-side.
5.  **Frontend (Streamlit)**: A polished, ChatGPT-style interface with chat persistence, saved playlists, and user history.

---

## ğŸš€ Features

*   **Semantic Search**: Find talks by concept (e.g., "AI ethics") not just keywords.
*   **Smart Recommendations**: Get personalized "Why this talk?" explanations for every suggestion.
*   **Structured Learning Paths**: Generate curated playlists for complex topics (e.g., "Beginner's Guide to Quantum Physics").
*   **Talk Comparison**: "Compare the talk by Simon Sinek vs. Brene Brown" â€“ get a structured analysis of themes and styles.
*   **Chat Persistence**: Auto-saves your conversations and organizes them by title (generated by LLM).
*   **User Personalization**: Tracks watch history and favorites to refine future recommendations.

---

## ğŸ› ï¸ Technology Stack

*   **Database**: Snowflake (Data Warehousing, Vector Search)
*   **AI/LLM**: Snowflake Cortex (`llama3.1-405b`, `snowflake-arctic-embed-m`)
*   **Orchestration**: Apache Airflow
*   **Transformation**: DBT (Data Build Tool)
*   **Agent Framework**: LangGraph / LangChain
*   **Frontend**: Streamlit
*   **Language**: Python 3.10+

---

## ğŸ“‚ Project Structure

```bash
ted_ai_project/
â”œâ”€â”€ airflow/               # Airflow DAGs & Scripts
â”‚   â”œâ”€â”€ dags/              # ETL Pipelines (S3 Ingestion, Scrapers)
â”‚   â””â”€â”€ docker-compose.yml # Airflow Infrastructure
â”œâ”€â”€ dbt/                   # DBT Project
â”‚   â”œâ”€â”€ models/            # SQL Models (Staging, Curated, Semantic)
â”‚   â””â”€â”€ profiles/          # Connection Profiles
â”œâ”€â”€ snowflake/             # Database Infrastructure (IaC)
â”‚   â””â”€â”€ final_ddl/         # Consolidated DDL for all schemas
â”œâ”€â”€ streamlit_app/         # Frontend Application
â”‚   â”œâ”€â”€ app.py             # Main Entry Point
â”‚   â”œâ”€â”€ langgraph_agents.py# AI Agent Definitions
â”‚   â””â”€â”€ db.py              # Snowflake Interaction Layer
â””â”€â”€ common/                # Shared Utilities
```

---

## âš¡ Setup & Usage

### Prerequisites
*   Python 3.10+
*   Snowflake Account (with Cortex enabled)
*   Docker (for Airflow)

### 1. Environment Setup
Create a `.env` file in the root directory (see `.env.example`):
```text
SNOWFLAKE_ACCOUNT=...
SNOWFLAKE_USER=...
SNOWFLAKE_PASSWORD=...
SNOWFLAKE_ROLE=TRAINING_ROLE
SNOWFLAKE_WAREHOUSE=TED_AGENT_WH
SNOWFLAKE_DATABASE=TED_DB
SNOWFLAKE_SCHEMA=APP
```

### 2. Run the Application
Navigate to the app directory and launch Streamlit:
```bash
cd streamlit_app
pip install -r requirements.txt
streamlit run app.py
```

### 3. (Optional) Run Airflow Pipeline
To trigger a fresh data ingestion:
```bash
cd airflow
docker-compose up -d
# Access Airflow UI at localhost:8080 (admin/admin)
```

---

## ğŸ›¡ï¸ Security

*   **Credentials**: All sensitive keys are managed via `.env` files and strictly excluded from version control.
*   **RBAC**: Snowflake access is governed by the `TRAINING_ROLE` with least-privilege access.
*   **Public Key Auth**: Snowflake connections use Key-Pair authentication where possible for enhanced security.
